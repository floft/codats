#!/bin/bash
#SBATCH --job-name=AdvConf
#SBATCH --output=slurm_logs/train_%j.out
#SBATCH --error=slurm_logs/train_%j.err
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=7
#SBATCH --nodes=1-1
#SBATCH --gres=gpu:1
#SBATCH --partition=taylor
#SBATCH --time=1-00:00:00
#SBATCH --mem=30G

#
# This script trains one network
#

. kamiak_config.sh

# For on my own computer
remotedir="$localdir"  # for use on my own computer
# SBATCH --cpus-per-task=7
# SBATCH --partition=taylor
# SBATCH --mem=30G
# For actual use on Kamiak...
# SBATCH --cpus-per-task=3
# SBATCH --partition=taylor,cahnrs_gpu,free_gpu,hpc_club,kamiak
# SBATCH --mem=20G

# Errors
handle_terminate() {
    echo "Exiting"
    exit 1
}
handle_error() {
    echo "Error occured -- exiting"
    exit 1
}
trap 'handle_terminate' SIGTERM SIGINT

# Suffix
first_arg=$1
if [[ -z $first_arg ]]; then
    echo "Specify what method to use, e.g. --model=flat"
    exit 1
else
    echo "Args: $@"
fi

# Allow overriding args. Other args are passed directly to the Python program.
program_args=()
for i; do
    name="$(cut -d'=' -f1 <<< "$i")"
    value="$(cut -d'=' -f2 <<< "$i")"

    if [[ "$name" == "--logdir" ]]; then
        logFolder="$value"
        echo "Overriding logdir to be: $logFolder"
    elif [[ "$name" == "--modeldir" ]]; then
        modelFolder="$value"
        echo "Overriding modeldir to be: $modelFolder"
    else
        program_args+=("$i")
    fi

    shift
done

# Depends
export OMP_NUM_THREADS=$SLURM_CPUS_PER_TASK
module load cuda/9.0.176 cudnn/7.1.2_cuda9.0 python3/3.6.5
# I upgraded tensorflow with:
#   module load python3/3.6.5
#   pip install --user --upgrade --no-cache-dir tensorflow-gpu==2.0.0-alpha0 pillow lxml jupyter matplotlib pandas sklearn scipy
pip install --user tensorflow-gpu==2.0.0-alpha0 pillow lxml jupyter matplotlib pandas sklearn scipy

# Train
cd "$remotedir"
mkdir -p "$logFolder/"
python3 main.py --logdir "$remotedir/$logFolder" --modeldir "$remotedir/$modelFolder" \
    --gpumem=0.8 "${program_args[@]}" || handle_error
